{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "1_autokeras_notebook_1_st_examples.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dnk_2iUURsZq"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usI8AUxGRsZn",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        "\n",
        "![huawei-logo](https://www-file.huawei.com/-/media/corporate/images/home/logo/huawei_logo.png)\n",
        "\n",
        "<p><b>Летняя школа. \"Современные методы теории информации, оптимизации и управления\".</p></b>\n",
        "Sirius-2020.\n",
        "<center> <b>Авторы материала: к.т.н. Антонов Лев, Власов Роман."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6xMu-QGXPVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1  &> /dev/null\n",
        "!pip install autokeras  &> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnk_2iUURsZq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Практическое знакомство с AutoKeras\n",
        "![autokeras-logo](https://camo.githubusercontent.com/5eedb6a5c3303767497912731e006b662bf83490/68747470733a2f2f6175746f6b657261732e636f6d2f696d672f726f775f7265642e737667)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE2TUxQbRsZt",
        "colab_type": "text"
      },
      "source": [
        "Одной из самых новых и мощных концепций на сегодняшний день является направление ___\"Поиск нейросетевых архитектур\" (Neural Architecture Search (NAS))___. NAS - это, по сути, метод устранения ограничений человечских знаний и эвристик при ручном построении архитектур нейронных сетей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmuVfljORsZv",
        "colab_type": "text"
      },
      "source": [
        "Чтобы успешно использовать NAS в прошлом, требовались очень сложные реализации сценариев Tensorflow, PyTorch или Keras. Помимо этого, рассчитать требования к оборудованию на уровне предприятия. Для упрощения задачи поиска команда разработчиков из \"Texas A & M Lab\" разработала платформу с открытым исходным кодом, созданную с помощью Keras, чтобы предоставить возможность использовать NAS любому заядлому пользователю Keras + python. \n",
        "Версия 1.0 платформы **AutoKeras** была выпущена только в январе 2019 года после года, предшествующего предварительным версиям, что позволило ей выйти без большого количества багов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbUOLunFRsZx",
        "colab_type": "text"
      },
      "source": [
        "В библиотеке используются **самые современные алгоритмы NAS**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfEEJ-MLRsZy",
        "colab_type": "text"
      },
      "source": [
        "AutoKeras поддерживает несколько стандартных конструкций, обладающих чрезвычайно простым интерфейсом, для решения ряда распространенных задач:\n",
        "* Классификация изображений (**ImageClassifier**).\n",
        "* Регрессия изображения (**ImageRegressor**).\n",
        "* Классификация текста (**TextClassifier**).\n",
        "* Регрессия текста (**TextRegressor**).\n",
        "* Классификация структурированных данных (**StructuredDataClassifier**).\n",
        "* Регрессия структурированных данных (**StructuredDataRegressor**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSKmynmJRsZ1",
        "colab_type": "text"
      },
      "source": [
        "Также есть возможность настроить собственную модель в ручном режиме.\n",
        "Для этого в AutoKeras предусмотрен класс **AutoModel**.\n",
        "Здесь присутствует возможность тонкой настройки алгоритма и указание списка конкретных блоков, на которые алгоритм должен обратить внимание в первую очередь при построении моделей.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7azTtdCRsZ-",
        "colab_type": "text"
      },
      "source": [
        "**Nodes** (Список возможных входных блоков):\n",
        "* ImageInput\n",
        "* Input\n",
        "* StructuredDataInput\n",
        "* TextInput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zn4MC7pRsaB",
        "colab_type": "text"
      },
      "source": [
        "**Blocks** (Список блоков - потенциальных скрытых слоев модели) :\n",
        "* ImageAugmentation\n",
        "* Normalization\n",
        "* TextToIntSequence\n",
        "* TextToNgramVector\n",
        "* CategoricalToNumerical\n",
        "* ConvBlock\n",
        "* DenseBlock\n",
        "* Embedding\n",
        "* Merge\n",
        "* ResNetBlock\n",
        "* RNNBlock\n",
        "* SpatialReduction\n",
        "* TemporalReduction\n",
        "* XceptionBlock\n",
        "* ImageBlock\n",
        "* StructuredDataBlock\n",
        "* TextBlock\n",
        "* ClassificationHead\n",
        "* RegressionHead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnV8DsPxRsaC",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwGZy4mRRsaE",
        "colab_type": "text"
      },
      "source": [
        "Первый шаг - подготовка данных. Здесь мы используем набор данных MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jzHJs3URsaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a40e1c68-9064-44eb-be2a-ff2453c9437f"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "import autokeras as ak\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "print(y_train.shape)  # (60000,)\n",
        "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "[5 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgXL5aHiCjBU",
        "colab_type": "text"
      },
      "source": [
        "Указываем путь, по которому будут храниться история и логи поиска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPdbnkVPRsaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_PATH = \"0_0_AutoMLArchSearchClassiferMNIST/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvqTeBGCv-5m",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTlAdiWx_lG0",
        "colab_type": "text"
      },
      "source": [
        "**Разберем параметры класса**\n",
        "\n",
        "``` python\n",
        "\n",
        "autokeras.ImageClassifier(\n",
        "    num_classes=None, # По умолчанию None. Если None, это будет выведено из данных.\n",
        "    multi_label=False,\n",
        "    loss=None,        # функция потери Кераса. По умолчанию используется «binary_crossentropy» \n",
        "                      # или «categoryorical_crossentropy» в зависимости от количества классов.\n",
        "    \n",
        "    metrics=None,     # список метрик Кераса. По умолчанию используется «точность».\n",
        "    project_name=\"image_classifier\",\n",
        "    max_trials=100,   # Максимальное количество различных моделей Keras,которые можно попробовать. \n",
        "                      # Поиск может завершиться до достижения max_trials. По умолчанию 100. \n",
        "    directory=None,\n",
        "    objective=\"val_loss\", # Имя метрики модели для минимизации или максимизации, например, «val_accuracy». \n",
        "                          # По умолчанию «val_loss».\n",
        "    tuner=None,       # строка или подкласс модуля AutoTuner. \n",
        "                      # Если строка, то значения должны быть следующие 'greedy', 'bayesian', 'hyperband' or 'random'.\n",
        "                      # По сути это выбор стратегии поиска архитектуры, выбор движка.\n",
        "                      # Если значение не указано, то алгоритм основываясь на понимании контекста задачи сам выбирает \n",
        "                      # стратегию поиска\n",
        "    overwrite=False,\n",
        "    seed=None,\n",
        "    **kwargs\n",
        ") \n",
        "``` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfDL-acQEl8L",
        "colab_type": "text"
      },
      "source": [
        "**Рассмотрим также параметры функции fit**\n",
        "\n",
        "``` python\n",
        "ImageClassifier.fit(\n",
        "    x=None,          # Union[numpy.ndarray, tensorflow.data.Dataset, None]\n",
        "                     # numpy.ndarray или tensorflow.Dataset.\n",
        "\n",
        "    y=None,          # Union[numpy.ndarray, tensorflow.data.Dataset, None]\n",
        "                     # numpy.ndarray или tensorflow.Dataset.\n",
        "\n",
        "    epochs=None,     # Количество эпох для обучения каждой модели при\n",
        "                     # поиске. Если не указано, по умолчанию максимально \n",
        "                     # модель обучается 1000 эпох, но мы прекращаем \n",
        "                     # обучение, если ошибка на валидации перестает\n",
        "                     # улучшаться в течение 10 эпох (если только вы не \n",
        "                     # указан параметр callbacks = EarlyStopping, в этом \n",
        "                     # случае EarlyStopping будет определить раннюю \n",
        "                     # остановку).\n",
        "\n",
        "    callbacks=None,  # Optional[List[tensorflow.keras.callbacks.Callback] \n",
        "                     # : список обратных вызовов Keras, применяемых во \n",
        "                     # время обучения и проверки.\n",
        "                     # может быть tf.keras.callbacks.EarlyStopping\n",
        "\n",
        "    validation_split=0.2, # По умолчанию 0.2. Доля данных обучения,\n",
        "                          # которые будут использоваться в качестве \n",
        "                          # данных проверки.\n",
        "\n",
        "    validation_data=None, # Явно переданный набор данных валидации\n",
        "    **kwargs\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnq69-sXRsad",
        "colab_type": "text"
      },
      "source": [
        "Далее инициализируем и запускаем **ImageClassifier**. Рекомендуется проводить больше испытаний для более сложных наборов данных. Это всего лишь небольшая демонстрация на наборе данных MNIST, поэтому устанавливаем **max_trials равным 1**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftyb1K1eRsae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "4da28337-e111-4658-9f21-786459df71af"
      },
      "source": [
        "# Initialize the image classifier.\n",
        "clf = ak.ImageClassifier(\n",
        "    directory  = OUTPUT_PATH,\n",
        "    overwrite  = True,\n",
        "    max_trials = 1)\n",
        "\n",
        "# Feed the image classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "print(predicted_y)\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 02m 38s]\n",
            "val_loss: 0.039189498871564865\n",
            "\n",
            "Best val_loss So Far: 0.039189498871564865\n",
            "Total elapsed time: 00h 02m 38s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1552 - accuracy: 0.9517\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0749 - accuracy: 0.9768\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0587 - accuracy: 0.9813\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0519 - accuracy: 0.9844\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0466 - accuracy: 0.9855\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0400 - accuracy: 0.9876\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0395 - accuracy: 0.9875\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0352 - accuracy: 0.9886\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0330 - accuracy: 0.9892\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0304 - accuracy: 0.9901\n",
            "[[7]\n",
            " [2]\n",
            " [1]\n",
            " ...\n",
            " [4]\n",
            " [5]\n",
            " [6]]\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9894\n",
            "[0.03403466194868088, 0.9894000291824341]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7UlF6AYRsav",
        "colab_type": "text"
      },
      "source": [
        "В AutoKeras реализованы такие модели, как **ResNet, Xception и отдельные CNN**, которые алгоритм может произвольно использовать и настраивать в любом месте синтезируемой модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO_bM5_0Rsaw",
        "colab_type": "text"
      },
      "source": [
        "По умолчанию AutoKeras использует **последние 20%** данных обучения в качестве валидационной выборки. Как показано в примере ниже, вы можете использовать **validation_split**, чтобы указать процент.\n",
        "\n",
        "```python\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        "    epochs=10,\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLRp2NwjRsa4",
        "colab_type": "text"
      },
      "source": [
        "Вы также можете использовать свой собственный набор проверки вместо отделения его от данных обучения, указав параметр **validation_data**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILVrvRUtRsa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de1c3274-3cb8-4a9c-e17e-60fd5eb9843e"
      },
      "source": [
        "split = 50000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=10,\n",
        ")\n",
        "x_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOGZ0TxqoOzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Сохранять полученные результаты будем следующим образом:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwuBJrZURsa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "188daf33-255b-490a-e74c-b1435fd8ab6e"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# экспортируем лучшую синтезированную модель\n",
        "model = clf.export_model()\n",
        "model_json = model.to_json()\n",
        "# сохраняем в json-формате\n",
        "with open(OUTPUT_PATH + '/autoML.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# сохраняем коэффициенты\n",
        "model.save_weights(OUTPUT_PATH + \"/model.h5\")\n",
        "print(\"Model saved to the disk\")\n",
        "\n",
        "predicted = model.predict(x_val)\n",
        "report = classification_report(y_val, np.argmax(predicted, 1))\n",
        "\n",
        "p = os.path.join(os.path.dirname(OUTPUT_PATH), 'results.txt')\n",
        "f = open(p, 'w')\n",
        "f.write(report)\n",
        "f.close()\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model saved to the disk\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       991\n",
            "           1       1.00      1.00      1.00      1064\n",
            "           2       1.00      1.00      1.00       990\n",
            "           3       1.00      1.00      1.00      1030\n",
            "           4       1.00      0.99      1.00       983\n",
            "           5       1.00      1.00      1.00       915\n",
            "           6       1.00      1.00      1.00       967\n",
            "           7       1.00      1.00      1.00      1090\n",
            "           8       1.00      1.00      1.00      1009\n",
            "           9       0.99      1.00      1.00       961\n",
            "\n",
            "    accuracy                           1.00     10000\n",
            "   macro avg       1.00      1.00      1.00     10000\n",
            "weighted avg       1.00      1.00      1.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSdUAoOORsbB",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на синтезированную модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbsu9nyRsbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "bf7d4350-7f32-4144-db55-f90805ba9b7c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 28, 28, 1)         3         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                92170     \n",
            "_________________________________________________________________\n",
            "classification_head_1 (Softm (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 110,989\n",
            "Trainable params: 110,986\n",
            "Non-trainable params: 3\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4Jl1mFmRsbZ",
        "colab_type": "text"
      },
      "source": [
        "## Customized Search Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ptlMy3bRsbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_PATH_1 = \"0_1_AutoMLArchSearchAutoModelMNIST/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Re_UTVRRsbf",
        "colab_type": "text"
      },
      "source": [
        "Опытные пользователи могут настроить пространство поиска, используя класс **AutoModel** вместо **ImageClassifier**. Здесь есть возможность настроить **ImageBlock** для некоторых высокоуровневых конфигураций, например, **block_type** - тип нейронной сети для поиска, выполнять ли нормализацию данных, и т.д. Вы также можете не указывать эти аргументы, тогда различные варианты будут настраиваться автоматически. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9-afd3yRsbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "62c67c2e-480b-499b-e103-660eac4fc903"
      },
      "source": [
        "input_node = ak.ImageInput()\n",
        "output_node = ak.ImageBlock(\n",
        "    # Only search ResNet architectures.\n",
        "    block_type=\"resnet\",\n",
        "    # Normalize the dataset.\n",
        "    normalize=True,\n",
        "    # Do not do data augmentation.\n",
        "    augment=False,\n",
        ")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "clf = ak.AutoModel(\n",
        "    directory  = OUTPUT_PATH_1,\n",
        "    inputs=input_node,\n",
        "    outputs=output_node,\n",
        "    overwrite=True,\n",
        "    max_trials=1)\n",
        "\n",
        "clf.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 21m 53s]\n",
            "val_loss: 0.13894148170948029\n",
            "\n",
            "Best val_loss So Far: 0.13894148170948029\n",
            "Total elapsed time: 00h 21m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.3946 - accuracy: 0.9100\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 151s 96ms/step - loss: 0.2824 - accuracy: 0.9433\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 151s 97ms/step - loss: 0.2243 - accuracy: 0.9533\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.1751 - accuracy: 0.9627\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.1278 - accuracy: 0.9692\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.1533 - accuracy: 0.9647\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 151s 97ms/step - loss: 0.1125 - accuracy: 0.9719\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 151s 97ms/step - loss: 0.1579 - accuracy: 0.9688\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 151s 97ms/step - loss: 0.2030 - accuracy: 0.9593\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.0937 - accuracy: 0.9746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I85aE61GxKXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "9a7116c9-1fdd-4ff6-9b0a-fd151c557bce"
      },
      "source": [
        "# экспортируем лучшую синтезированную модель\n",
        "model = clf.export_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "normalization (Normalization)   (None, 28, 28, 1)    3           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing (Resizing)             (None, 32, 32, 1)    0           normalization[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 3)    0           resizing[0][0]                   \n",
            "                                                                 resizing[0][0]                   \n",
            "                                                                 resizing[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resnet50 (Model)                (None, 1, 1, 2048)   23587712    concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           resnet50[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           20490       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "classification_head_2 (Softmax) (None, 10)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 23,608,205\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,123\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0cvu0VdRsbj",
        "colab_type": "text"
      },
      "source": [
        "Использование AutoModel аналогично функциональному API Keras. По сути, вы строите граф, ребра которого являются блоками, а узлы - промежуточными выходами блоков. **Чтобы добавить ребро из input_node в output_node необходимо сделать следующее: output_node = ak.some_block(input_node)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsdcAmxRRsbj",
        "colab_type": "text"
      },
      "source": [
        "Вы также можете использовать более мелкие блоки для дальнейшей настройки пространства поиска."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZKYtIdjRsbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "34259204-b002-448e-bda0-279ded7c2160"
      },
      "source": [
        "OUTPUT_PATH_2 = \"0_2_AutoMLArchSearchAutoModelMNIST/\"\n",
        "\n",
        "input_node = ak.ImageInput()\n",
        "output_node = ak.Normalization()(input_node)\n",
        "output_node = ak.ImageAugmentation(horizontal_flip=False)(output_node)\n",
        "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    directory  = OUTPUT_PATH_2,\n",
        "    inputs=input_node,\n",
        "    outputs=output_node,\n",
        "    overwrite=True,\n",
        "    max_trials=1)\n",
        "clf.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 08m 01s]\n",
            "val_loss: 0.7793896198272705\n",
            "\n",
            "Best val_loss So Far: 0.7793896198272705\n",
            "Total elapsed time: 00h 08m 01s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 1.1632 - accuracy: 0.6194\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.9478 - accuracy: 0.6888\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.9088 - accuracy: 0.7007\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8818 - accuracy: 0.7087\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8756 - accuracy: 0.7114\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8643 - accuracy: 0.7149\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8506 - accuracy: 0.7175\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8511 - accuracy: 0.7182\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8442 - accuracy: 0.7212\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.8426 - accuracy: 0.7203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBBwoLnwRsbv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN1AT26lRsbx",
        "colab_type": "text"
      },
      "source": [
        "Здесь важно отметить, что блоки не являются последовательными, даже если они выглядят так, как в коде. Их можно рассматривать как дополнительные сервисы и указатели для AutoModel в каждой строке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFOaI_iRRsbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "57a834bb-8494-4db3-befb-62d58e393c2c"
      },
      "source": [
        "# экспортируем лучшую синтезированную модель\n",
        "model = clf.export_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "normalization (Normalization)   (None, 28, 28, 1)    3           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "random_flip (RandomFlip)        (None, 28, 28, 1)    0           normalization[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "resizing (Resizing)             (None, 32, 32, 1)    0           random_flip[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 3)    0           resizing[0][0]                   \n",
            "                                                                 resizing[0][0]                   \n",
            "                                                                 resizing[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resnet50v2 (Model)              multiple             23564800    concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           resnet50v2[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           20490       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "classification_head_1 (Softmax) (None, 10)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 23,585,293\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,803\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}